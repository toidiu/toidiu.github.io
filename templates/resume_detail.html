{% extends "index.html" %}

{% block extra_head %}
{% endblock extra_head %}

{% block content %}
  <div class="main-container">

    - Worked closely with Data Science/Design/iOS to help launch music recommendaRon service and make it more resilient.
        - migrating old recs api to new micro service logic
        - HA for data published by DS
        - realizing fastly was caching recs
          - change from blacklist to whitelist and rolling it out in production

    - debugging and optimizing Mongo query performance across different services
    - write unit and mongo embed tests across the many services
    - I interface with kubernetes on a daily basis. k8s is quite complex so many of the debugging tasks involve creating and refining the mental picture of how it actually works. This is then used to debug and further improve upon service performance.



    <p><strong>Access and expose data recommendations generated by Data Science (DS).</strong></p>
    <p>=== Problem statement:<br />Data Science (DS) ran a nightly job to generate music recommendations for users. The dataset would live in DynamoDB and the old DS workflow was to rewrite the same dynamo table with new dataset each night. This was a high risk operation for the my team (APIs). Additionally it caused some outages due to accidental schema changes.</p>
    <p>I was in charge of creating a HA and resilient workflow.</p>
    <p>=== Design:</p>
    <ul>
      <li>Treat data as immutable
        <ul>
          <li>Enforce that DS publish the dataset to a new table each night</li>
          <li>This gives the benefit of 'rollback' if a new dataset was broken</li>
        </ul>
      </li>
      <li>Given multiple datasets (a,b,c); DS can 'point' to latest dataset
        <ul>
          <li>DS can maintain a few versions of the data. "Version Table"</li>
          <li>DS can run tests on new datasets to confirm schema compatibility</li>
          <li>rollbacks are as easy as pointing to an older known dataset</li>
        </ul>
      </li>
      <li>Maintain a log of actions (publish new dataset, test pass/fail, point to new dataset)</li>
    </ul>
    <p>=== Tasks performed:</p>
    <ul>
      <li>Work closely with DS to come up with the system design.</li>
      <li>Added a Jenkins tests which could be triggered by DS
        <ul>
          <li>used to verify that data schema would not be a breaking change</li>
          <li>extensible model for other types of tests</li>
          <li>potential to track failing/passing metrics</li>
        </ul>
      </li>
      <li>Poll based mechanism within API code to look at "Version Table" and start using the latest dataset.
        <ul>
          <li>A poll interval of 5 min was used since 'older' data would still produce good enough data.</li>
          <li>Log when a new dataset was detected (help correlate errors with new dataset)&nbsp;</li>
        </ul>
      </li>
    </ul>

  </div>
{% endblock content %}

{% block nav %}
  {# no nav #}
{% endblock nav %}

{% block footer %}
  {# no footer #}
{% endblock footer %}
